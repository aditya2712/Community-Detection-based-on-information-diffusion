{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yl4x5cA1SNG9",
        "QDlDK27kwEPz",
        "O2bDq1zrfTQj",
        "RM5N1IP4EYwR",
        "p2cWBMtjNa8k",
        "92NDUWhhNvre",
        "73MP4oSKOOPT",
        "YpKalot-ORCA",
        "ST6FXZLfhIwo",
        "T8SmBWNSQn7U"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "yl4x5cA1SNG9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqqNbLYfpM3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05942e93-5beb-43fd-aba9-275834df3cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ndlib\n",
            "  Downloading ndlib-5.1.1-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.2/110.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting netdispatch (from ndlib)\n",
            "  Downloading netdispatch-0.1.0-py3-none-any.whl (3.3 kB)\n",
            "Collecting python-igraph (from ndlib)\n",
            "  Downloading python-igraph-0.10.4.tar.gz (9.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ndlib) (1.22.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from ndlib) (3.1)\n",
            "Collecting dynetx (from ndlib)\n",
            "  Downloading dynetx-0.3.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ndlib) (1.10.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from ndlib) (2.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ndlib) (0.18.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->ndlib) (3.1.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->ndlib) (23.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->ndlib) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->ndlib) (6.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->ndlib) (6.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->ndlib) (4.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dynetx->ndlib) (4.65.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from dynetx->ndlib) (4.4.2)\n",
            "Collecting igraph==0.10.4 (from python-igraph->ndlib)\n",
            "  Downloading igraph-0.10.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting texttable>=1.6.2 (from igraph==0.10.4->python-igraph->ndlib)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->ndlib) (2.1.2)\n",
            "Building wheels for collected packages: python-igraph\n",
            "  Building wheel for python-igraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-igraph: filename=python_igraph-0.10.4-py3-none-any.whl size=9073 sha256=1a496c34cfc0c63d8a6b67b0f7a0541b03cdbd90b7fdc5f88f7533ddd6a81cd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/27/15/dcf90953e3e3322e6f3e447514b20cf39b53c6518cb4a7bace\n",
            "Successfully built python-igraph\n",
            "Installing collected packages: texttable, igraph, dynetx, python-igraph, netdispatch, ndlib\n",
            "Successfully installed dynetx-0.3.1 igraph-0.10.4 ndlib-5.1.1 netdispatch-0.1.0 python-igraph-0.10.4 texttable-1.6.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cdlib\n",
            "  Downloading cdlib-0.2.6-py3-none-any.whl (228 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.6/228.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cdlib) (1.22.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from cdlib) (0.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from cdlib) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from cdlib) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cdlib) (4.65.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from cdlib) (3.1)\n",
            "Collecting demon (from cdlib)\n",
            "  Downloading demon-2.0.6-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: python-louvain>=0.16 in /usr/local/lib/python3.10/dist-packages (from cdlib) (0.16)\n",
            "Collecting nf1 (from cdlib)\n",
            "  Downloading nf1-0.0.4-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from cdlib) (1.10.1)\n",
            "Collecting pulp (from cdlib)\n",
            "  Downloading PuLP-2.7.0-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from cdlib) (0.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from cdlib) (1.5.3)\n",
            "Collecting eva-lcd (from cdlib)\n",
            "  Downloading eva_lcd-0.1.1-py3-none-any.whl (9.2 kB)\n",
            "Collecting bimlpa (from cdlib)\n",
            "  Downloading bimlpa-0.1.2-py3-none-any.whl (7.0 kB)\n",
            "Collecting markov-clustering (from cdlib)\n",
            "  Downloading markov_clustering-0.0.6.dev0-py3-none-any.whl (6.3 kB)\n",
            "Collecting chinese-whispers (from cdlib)\n",
            "  Downloading chinese_whispers-0.8.1-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: python-igraph in /usr/local/lib/python3.10/dist-packages (from cdlib) (0.10.4)\n",
            "Collecting angel-cd (from cdlib)\n",
            "  Downloading angel_cd-1.0.3-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from cdlib) (1.6.0)\n",
            "Requirement already satisfied: dynetx in /usr/local/lib/python3.10/dist-packages (from cdlib) (0.3.1)\n",
            "Collecting thresholdclustering (from cdlib)\n",
            "  Downloading thresholdclustering-1.1-py3-none-any.whl (5.3 kB)\n",
            "Collecting pyclustering (from cdlib)\n",
            "  Downloading pyclustering-0.10.1.2.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cdlib) (0.29.34)\n",
            "Collecting python-Levenshtein (from cdlib)\n",
            "  Downloading python_Levenshtein-0.21.0-py3-none-any.whl (9.4 kB)\n",
            "Collecting networkx>=2.4 (from cdlib)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from dynetx->cdlib) (4.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cdlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cdlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cdlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cdlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cdlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cdlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cdlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->cdlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->cdlib) (2022.7.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch->cdlib) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch->cdlib) (2.27.1)\n",
            "Requirement already satisfied: igraph==0.10.4 in /usr/local/lib/python3.10/dist-packages (from python-igraph->cdlib) (0.10.4)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from igraph==0.10.4->python-igraph->cdlib) (1.6.7)\n",
            "Collecting Levenshtein==0.21.0 (from python-Levenshtein->cdlib)\n",
            "  Downloading Levenshtein-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.0->python-Levenshtein->cdlib)\n",
            "  Downloading rapidfuzz-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->cdlib) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->cdlib) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->cdlib) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->cdlib) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->cdlib) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->cdlib) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->cdlib) (3.4)\n",
            "Building wheels for collected packages: pyclustering\n",
            "  Building wheel for pyclustering (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyclustering: filename=pyclustering-0.10.1.2-py3-none-any.whl size=2395106 sha256=4cd46b6290ccaad847c7066edf1db6d51bb3da509d814d5a0c6fd31d021a8ab2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/42/97/11eee99f5c1e4fdfc170f0a54f9c9eb195df66edb4cf69f449\n",
            "Successfully built pyclustering\n",
            "Installing collected packages: pulp, rapidfuzz, networkx, thresholdclustering, Levenshtein, eva-lcd, demon, chinese-whispers, python-Levenshtein, pyclustering, nf1, markov-clustering, bimlpa, angel-cd, cdlib\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "Successfully installed Levenshtein-0.21.0 angel-cd-1.0.3 bimlpa-0.1.2 cdlib-0.2.6 chinese-whispers-0.8.1 demon-2.0.6 eva-lcd-0.1.1 markov-clustering-0.0.6.dev0 networkx-2.8.8 nf1-0.0.4 pulp-2.7.0 pyclustering-0.10.1.2 python-Levenshtein-0.21.0 rapidfuzz-3.0.0 thresholdclustering-1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ndlib\n",
        "!pip install cdlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from igraph import *\n",
        "import community\n",
        "import ndlib.models.ModelConfig as mc\n",
        "import ndlib.models.epidemics as ep\n",
        "import matplotlib.pyplot as plt\n",
        "import cdlib\n",
        "from cdlib import algorithms, NodeClustering\n",
        "from cdlib import evaluation\n",
        "import numpy as np\n",
        "from networkx.classes.function import common_neighbors\n",
        "from cdlib import evaluation, algorithms\n",
        "from cdlib.utils import convert_graph_formats, __from_nx_to_graph_tool, affiliations2nodesets, nx_node_integer_mapping\n",
        "import community as louvain_modularity\n",
        "from networkx.generators.community import LFR_benchmark_graph\n",
        "from collections import defaultdict\n",
        "import math\n",
        "from math import comb\n",
        "import random\n",
        "from networkx.algorithms.components.connected import connected_components\n",
        "import time\n",
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "import copy\n",
        "import operator as op\n",
        "from functools import reduce"
      ],
      "metadata": {
        "id": "voslF6_0p7No",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb0193a-deaa-4780-c4ea-e6fe3bf5713d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: to be able to use all crisp methods, you need to install some additional packages:  {'wurlitzer', 'karateclub', 'leidenalg', 'infomap', 'graph_tool'}\n",
            "Note: to be able to use all overlapping methods, you need to install some additional packages:  {'karateclub', 'ASLPAw'}\n",
            "Note: to be able to use all bipartite methods, you need to install some additional packages:  {'wurlitzer', 'infomap', 'leidenalg'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quality matrix"
      ],
      "metadata": {
        "id": "4VWcG0yCwBvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def community_coverage(G, comm):\n",
        "    # Community coverage should be more\n",
        "    nodes_in_com = 0\n",
        "    for n in G.nodes():\n",
        "        for c in comm:\n",
        "            if n in c and len(c)>=3:\n",
        "                nodes_in_com += 1;\n",
        "                break;\n",
        "    \n",
        "    return nodes_in_com/len(G.nodes())\n",
        "\n",
        "\n",
        "def overlap_coverage(G, comm):\n",
        "    total = 0\n",
        "    for n in G.nodes():\n",
        "        for c in comm:\n",
        "            if n in c and len(c)>=3:\n",
        "                total += 1;\n",
        "    \n",
        "    return total/len(G.nodes())\n",
        "\n",
        "\n",
        "def extended_modularity(G, clusters):\n",
        "    sum1 = 0\n",
        "    n_comm = defaultdict(lambda: 0)  # {node: num of communities it is in}\n",
        "    for comm in clusters:\n",
        "        for node in comm:\n",
        "            n_comm[node] = n_comm[node] + 1\n",
        "\n",
        "    degree = G.degree()\n",
        "    m2 = G.number_of_edges() * 2\n",
        "    m = 0\n",
        "    for U in clusters:\n",
        "        i=0\n",
        "        sum1=0\n",
        "        while i < len(U):\n",
        "            j = i + 1\n",
        "            while j < len(U):\n",
        "                x = (G.has_edge(U[i], U[j]) - ((G.degree(U[i]) * G.degree(U[j])) / (m2)))  / (\n",
        "                            n_comm[U[i]] * n_comm[U[j]])\n",
        "                sum1 = sum1 +  2*x\n",
        "                j = j + 1\n",
        "            i = i + 1\n",
        "        m = m + sum1\n",
        "\n",
        "    m = m / (m2)  # compute the final modularity\n",
        "    return (m)\n",
        "\n",
        "\n",
        "def modularity_overlap(G, comm):\n",
        "    def ncr(n, r):\n",
        "        r = min(r, n-r)\n",
        "        numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
        "        denom = reduce(op.mul, range(1, r+1), 1)\n",
        "        return numer // denom  \n",
        "\n",
        "    n_comm = defaultdict(lambda: 0)  # {node: num of communities it is in}\n",
        "    for c in comm:\n",
        "        for node in c:\n",
        "            n_comm[node] = n_comm[node] + 1\n",
        "\n",
        "    mod_C = len(comm)\n",
        "    num = 0\n",
        "    for c in comm:\n",
        "        nc = len(c)\n",
        "        nec = 0\n",
        "        for i in c:\n",
        "            for j in c:\n",
        "                if G.has_edge(i, j):\n",
        "                    nec += 1\n",
        "\n",
        "        num_num = 0\n",
        "        for i in c:\n",
        "            in_comm_connections = 0\n",
        "            for j in c:\n",
        "                if i != j and G.has_edge(i, j):\n",
        "                    in_comm_connections += 1\n",
        "            \n",
        "            out_comm_connections = 0\n",
        "            for j in G.nodes():\n",
        "                if j not in c and j != i and G.has_edge(i, j):\n",
        "                    out_comm_connections += 1\n",
        "            \n",
        "            num_num += ((in_comm_connections - out_comm_connections)/(G.degree(i)*n_comm[i]))\n",
        "        \n",
        "        num += ((num_num*nec)/(nc*ncr(nc, 2)))\n",
        "            \n",
        "    return num/mod_C\n",
        "\n",
        "\n",
        "def overlapping_modularity(G, comm):\n",
        "    N = G.number_of_edges() * 2\n",
        "    res = comm # list of communities\n",
        "    m=0\n",
        "    for U in res:\n",
        "        n=len(U);\n",
        "        \n",
        "        S=G.subgraph(U)\n",
        "        \n",
        "        rr=[]\n",
        "        for kk in res:\n",
        "            if not kk==U:\n",
        "                rr.extend(kk)\n",
        "        \n",
        "        ov=list(set(U).intersection(set(rr)))\n",
        "        \n",
        "        sum1 = 0\n",
        "        i = 0\n",
        "\n",
        "        while i<len(U):\n",
        "            j=i+1\n",
        "            while j<len(U):\n",
        "                if U[i] in ov:\n",
        "                    o=S.degree(U[i])\n",
        "                    o1=0\n",
        "                    for ll in res:\n",
        "                        if U[i] in ll:\n",
        "                            S1=G.subgraph(ll)\n",
        "                            o1=o1+S1.degree(U[i])\n",
        "                    al1=o/o1\n",
        "                else :   \n",
        "                    al1=1\n",
        "\n",
        "                if  U[j] in ov:\n",
        "                    oo=S.degree(U[j])\n",
        "                    oo1=0\n",
        "                    for ll in res:\n",
        "                        if U[j]in ll:\n",
        "                            S1=G.subgraph(ll)\n",
        "                            oo1=oo1+S1.degree(U[j]) \n",
        "                    al2=oo/oo1          \n",
        "                else :\n",
        "                    al2=1\n",
        "\n",
        "                x = ((G.has_edge(U[j], U[i])-((G.degree(U[i])*G.degree(U[j]))/(2*N)))*al1*al2)\n",
        "                sum1= sum1+2*x\n",
        "\n",
        "                j=j+1\n",
        "            i=i+1\n",
        "        m=m+sum1\n",
        "\n",
        "    m=m/(2*N) # compute the total modularity\n",
        "    \n",
        "    return (m)\n",
        "\n",
        "\n",
        "def overlapping_permanence(G):\n",
        "    mat = np.zeros(shape=(G.number_of_nodes(),G.number_of_nodes()))\n",
        "    for i in range (0,G.number_of_nodes()):\n",
        "        for j in range (0,G.number_of_nodes()):\n",
        "            if(G.has_edge(i,j)):\n",
        "                mat[i][j]=1  \n",
        "\n",
        "\n",
        "    def intersection(lst1,lst2):\n",
        "        temp=set(lst2)\n",
        "        lst3=[value for value in lst1 if value in temp]    \n",
        "        return lst3\n",
        "\n",
        "    def calc(G,community,v):\n",
        "        common=set(G[v])&set(community)\n",
        "        res = 0\n",
        "        for u in common:\n",
        "            share = 0\n",
        "            for c in cluster:\n",
        "                if v in c and u in c:\n",
        "                    share += 1\n",
        "            res += 1 / share\n",
        "        return res\n",
        "\n",
        "    def calc2(G,community,v):\n",
        "      res=set()\n",
        "      for c in cluster:\n",
        "          if v in c:\n",
        "              res|=set(G[v])&set(c)\n",
        "      return len(res)\n",
        "\n",
        "    def internal_clustering_coefficient(G,cluster,v):\n",
        "        nodes=intersection(cluster,nx.neighbors(G,v))\n",
        "        nodes.append(v);\n",
        "        H=G.subgraph(nodes)\n",
        "        internal_CC=nx.clustering(H)\n",
        "        b=calc(G,cluster,v)\n",
        "        c=calc2(G,cluster,v)\n",
        "        return internal_CC[v],b,c\n",
        "\n",
        "    C_in = {}\n",
        "    I = {}\n",
        "    Iv= {}\n",
        "\n",
        "    def cluster_update():\n",
        "        global C_in\n",
        "        global I\n",
        "        global Iv\n",
        "        C_in, I,Iv = {}, {},{}\n",
        "        for i in cluster:\n",
        "            for j in i:\n",
        "                a, b, Iv[j] = internal_clustering_coefficient(G, i, j)\n",
        "                if j not in C_in.keys():\n",
        "                    C_in[j] = []\n",
        "                if j not in I.keys():\n",
        "                    I[j] = []\n",
        "                C_in[j].append(a)\n",
        "                I[j].append(b)          \n",
        "\n",
        "    D=G.degree()\n",
        "    def External_conn_max(G,cluster,v):\n",
        "        res=0\n",
        "        for i in cluster:\n",
        "            if v not in i:\n",
        "                res=max(res,len(set(G[v])&set(i)))\n",
        "        return res\n",
        "\n",
        "    E_max={}\n",
        "    for i in G:\n",
        "        E_max[i]=External_conn_max(G,cluster,i)\n",
        "        \n",
        "    # Permanence\n",
        "    def permanence(E,D):\n",
        "        perm={}\n",
        "        cluster_update()\n",
        "        for i in I:\n",
        "            # print(i)\n",
        "            n = len(I[i])\n",
        "            # print(n)\n",
        "            for j in range(0, n): \n",
        "                # print(i,I[i][j],E[i],D[i],C_in[i][j],Iv[i])\n",
        "                if (i not in perm.keys()):\n",
        "                    perm[i] = 0\n",
        "                if(E_max[i]!=0):\n",
        "                    m = 1 if Iv[i] == 0 else (I[i][j]/Iv[i])\n",
        "          \n",
        "                    temp =((I[i][j]/E[i])*(1/D[i]))-((1-C_in[i][j])*(m))\n",
        "                    perm[i] += temp\n",
        "                    #print(\"permanence\", i, temp);\n",
        "                elif(D[i]==0 and E_max[i]==0):\n",
        "                    perm[i] +=0;\n",
        "                else:\n",
        "                    perm[i]+=1\n",
        "\n",
        "        #print(perm[0])\n",
        "        return perm\n",
        "\n",
        "    perm=permanence(E_max,D)\n",
        "    print(\"perm\",perm)\n",
        "    print(\"\\n\")\n",
        "    print(perm.values()) \n",
        "    print(\"\\n\")\n",
        "    print(np.sum(perm.values())) \n",
        "    perm_sum=(np.sum(perm.values()))\n",
        "    perml=list(perm_sum)\n",
        "    perma=np.mean(perml)\n",
        "    print(\"1. Average Permanance: \"+str(perma), \"\\n\")\n",
        "\n",
        "    #perm_avg= perm_sum/len(perm)\n",
        "    #print(\"Average Permanance: \"+str(perm_avg), \"\\n\")\n",
        "    print(\"Permanence of Nodes:\")\n",
        "    for i in perm:\n",
        "      print (\"Node\", i , \"=\", perm[i])\n",
        "      \n"
      ],
      "metadata": {
        "id": "9Di_BEklqzJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy Matrix"
      ],
      "metadata": {
        "id": "QDlDK27kwEPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nf1(comm1, comm2):\n",
        "    return evaluation.nf1(comm1, comm2)\n",
        "\n",
        "\n",
        "def onmi(comm1, comm2):\n",
        "    return evaluation.overlapping_normalized_mutual_information_LFK(comm1, comm2)\n",
        "\n",
        "\n",
        "def nmi_max(comm1, comm2):\n",
        "    return evaluation.overlapping_normalized_mutual_information_MGH(comm1, comm2)\n"
      ],
      "metadata": {
        "id": "dCqt9lGvwHk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ERCNS\n",
        "### Edge Reduction and Common Neighbor Selection"
      ],
      "metadata": {
        "id": "SiXLPvYw_8Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ERCNS(G, iter=0.2, neighbor_threshold=0.8):\n",
        "    OG = copy.deepcopy(G)\n",
        "\n",
        "    # plt.title('Original Graph', fontsize=40)\n",
        "    # nx.draw(G, with_labels=True, node_color='r')\n",
        "    # plt.show()\n",
        "    deg=G.degree()\n",
        "    n=len(deg)\n",
        "    edges = G.number_of_edges()\n",
        "\n",
        "    NUM_ITERATIONS = (int)(iter * edges)\n",
        "    for i in range(0, NUM_ITERATIONS):\n",
        "        edge_betweenness = nx.edge_betweenness_centrality(G).items()\n",
        "        edge_to_delete = sorted(edge_betweenness, key=lambda pair: -pair[1])[0][0]\n",
        "        G.remove_edge(*edge_to_delete)\n",
        "\n",
        "    com=nx.connected_components(G)\n",
        "    comm = []\n",
        "    for x in com:\n",
        "        comm.append(list(x))\n",
        "\n",
        "    com = comm\n",
        "\n",
        "    # count=1\n",
        "    # for i in com :\n",
        "    #     print(count, i)\n",
        "    #     count+=1\n",
        "    # plt.title('FINAL', fontsize=20)  \n",
        "    # nx.draw(G, with_labels=True, node_color='r')\n",
        "    # plt.show()\n",
        "\n",
        "    # Conversion of disjoint communities to overlapping communities\n",
        "    overlap_com = []\n",
        "    threshold=neighbor_threshold\n",
        "    for c in com:\n",
        "        temp_list = []\n",
        "        for n in c:\n",
        "            temp_list.append(n)\n",
        "            for nn in OG.neighbors(n):\n",
        "                # If the neighbor is already community, then skip it\n",
        "                if nn in c:\n",
        "                    continue\n",
        "                total_neighbor_count = len(list(OG.neighbors(n)))\n",
        "                in_c_count = 0\n",
        "                for nnn in OG.neighbors(n):\n",
        "                    if nnn in c:\n",
        "                        in_c_count += 1\n",
        "\n",
        "                if in_c_count/total_neighbor_count >= threshold and nn not in temp_list:\n",
        "                    temp_list.append(nn)\n",
        "        overlap_com.append(temp_list)\n",
        "\n",
        "    # print()\n",
        "    # print(\"__________After overlapping__________\")\n",
        "    # count=1\n",
        "    # for i in overlap_com :\n",
        "    #     print(count, i)\n",
        "    #     count+=1\n",
        "\n",
        "    # print()\n",
        "    # # Overlapping nodes:\n",
        "    # for i, x in enumerate(overlap_com): \n",
        "    #     if i != (len(overlap_com)-1):\n",
        "    #         overlap = set(overlap_com[i]).intersection(overlap_com[i+1])\n",
        "    #         print(f\"overlapping nodes between {i} and {i+1}: {overlap}\")\n",
        "    #         print(f\"length: {len(overlap)}\")\n",
        "\n",
        "    return overlap_com"
      ],
      "metadata": {
        "id": "763pky1F_lss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SLPA"
      ],
      "metadata": {
        "id": "O2bDq1zrfTQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is our implementation of SLPA\n",
        "# def SLPA(G):\n",
        "#     def node_importance(G, alpha):\n",
        "\n",
        "#         # Compute the eigenvector centrality for the graph\n",
        "#         ec = nx.eigenvector_centrality(G)\n",
        "\n",
        "#         # Compute the local and global properties for each node\n",
        "#         degrees = dict(G.degree())\n",
        "#         clustering = nx.clustering(G)\n",
        "\n",
        "#         # Compute the node importance using the given formula\n",
        "#         node_imp = {}\n",
        "#         for node in G.nodes():\n",
        "#             node_imp[node] = alpha * ec[node] + (1 - alpha) * (degrees[node] + clustering[node])\n",
        "\n",
        "#         return node_imp\n",
        "\n",
        "\n",
        "#     def label_propagation(G, node_imp):\n",
        "\n",
        "#         # Initialize each node with a unique label\n",
        "#         labels = {node: i for i, node in enumerate(G.nodes())}\n",
        "\n",
        "#         while True:\n",
        "#             # Shuffle the nodes in a random order\n",
        "#             nodes = list(G.nodes())\n",
        "#             np.random.shuffle(nodes)\n",
        "\n",
        "#             # Track whether any label has changed during this iteration\n",
        "#             changed = False\n",
        "\n",
        "#             # Propagate the labels to the neighbors of each node\n",
        "#             for node in nodes:\n",
        "#                 # Compute the frequencies of the labels among the neighbors\n",
        "#                 freq = {}\n",
        "#                 for neighbor in G.neighbors(node):\n",
        "#                     if labels[neighbor] not in freq:\n",
        "#                         freq[labels[neighbor]] = 0\n",
        "#                     freq[labels[neighbor]] += node_imp[neighbor]\n",
        "\n",
        "#                 # Assign the label with the highest frequency to the node\n",
        "#                 max_label = labels[node]\n",
        "#                 max_freq = freq.get(max_label, 0)\n",
        "#                 for label, frequency in freq.items():\n",
        "#                     if frequency > max_freq:\n",
        "#                         max_label = label\n",
        "#                         max_freq = frequency\n",
        "\n",
        "#                 # Update the label of the node if it has changed\n",
        "#                 if labels[node] != max_label:\n",
        "#                     labels[node] = max_label\n",
        "#                     changed = True\n",
        "\n",
        "#             # Exit the loop if no label has changed during this iteration\n",
        "#             if not changed:\n",
        "#                 break\n",
        "\n",
        "#         # Convert the labels into sets of nodes for each community\n",
        "#         communities = []\n",
        "#         for label in set(labels.values()):\n",
        "#             community = [node for node in G.nodes() if labels[node] == label]\n",
        "#             communities.append(community)\n",
        "\n",
        "#         return communities\n",
        "\n",
        "#     node_imp = node_importance(G, alpha=0.5)\n",
        "#     communities = label_propagation(G, node_imp)\n",
        "\n",
        "#     # overlap_com = []\n",
        "#     # for com in communities:\n",
        "#     #     print(list(com))\n",
        "#     #     overlap_com = overlap_com.append(list(com))\n",
        "#     return communities\n",
        "\n",
        "\n",
        "def SLPA(G, t=21, r=0.1):\n",
        "  coms = algorithms.slpa(G,  t, r)\n",
        "  overlap_com = coms.communities\n",
        "\n",
        "  return overlap_com"
      ],
      "metadata": {
        "id": "JX_hUyE-fSgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LPAM"
      ],
      "metadata": {
        "id": "RM5N1IP4EYwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LPAM(G, k=2, threshold=0.4, distance = \"amp\"):\n",
        "  coms = algorithms.lpam(G, k, threshold, distance)\n",
        "  overlap_com = coms.communities\n",
        "\n",
        "  return overlap_com"
      ],
      "metadata": {
        "id": "l5FArWFzEb_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Core Expansion"
      ],
      "metadata": {
        "id": "p2cWBMtjNa8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def core_expansion(G):\n",
        "  coms = algorithms.core_expansion(G)\n",
        "  overlap_com = coms.communities\n",
        "\n",
        "  return overlap_com"
      ],
      "metadata": {
        "id": "jMwdVHP7NgVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Walkscan"
      ],
      "metadata": {
        "id": "92NDUWhhNvre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def walkscan(G):\n",
        "  coms = algorithms.walkscan(G)\n",
        "  overlap_com = coms.communities\n",
        "\n",
        "  return overlap_com"
      ],
      "metadata": {
        "id": "00ETRHl-Nyk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PERCOMVC"
      ],
      "metadata": {
        "id": "73MP4oSKOOPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def percomvc(G):\n",
        "  coms = algorithms.percomvc(G)\n",
        "  overlap_com = coms.communities\n",
        "\n",
        "  return overlap_com"
      ],
      "metadata": {
        "id": "UYlbyd-1OJgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UMSTMO"
      ],
      "metadata": {
        "id": "YpKalot-ORCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def umstmo(G):\n",
        "  coms = algorithms.umstmo(G)\n",
        "  overlap_com = coms.communities\n",
        "\n",
        "  return overlap_com"
      ],
      "metadata": {
        "id": "znGNY6pkOQXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LPANNI"
      ],
      "metadata": {
        "id": "ST6FXZLfhIwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LPANNI(G):\n",
        "    coms = algorithms.lpanni(G)\n",
        "    overlap_com = coms.communities\n",
        "\n",
        "    return overlap_com"
      ],
      "metadata": {
        "id": "Fxo9U0TahKXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OCDID"
      ],
      "metadata": {
        "id": "T8SmBWNSQn7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def OCDID(G):  \n",
        "    jaccard_similarity = {}\n",
        "    clustering_coffecient = {}\n",
        "    average_degree = {}\n",
        "    average_similarity = {}\n",
        "    contact_strength = {}\n",
        "    information = {}\n",
        "    max_degree = max(len(list(G.neighbors(u))) for u in G.nodes())\n",
        "    # Information that can be propagated\n",
        "    def f(I_u, I_v):\n",
        "        if I_u-I_v < 0:\n",
        "            return 0\n",
        "        return math.exp(I_u-I_v)-1\n",
        "\n",
        "    # Inititalization\n",
        "    for v in G.nodes():\n",
        "        jaccard_similarity[v] = {}\n",
        "        contact_strength[v] = {}\n",
        "    for v in G.nodes():\n",
        "        neighbors_v = list(G.neighbors(v))\n",
        "        no_of_neighbor_v = len(neighbors_v)\n",
        "        # computing jaccaed similarity\n",
        "        for u in neighbors_v :\n",
        "            neighbors_u = list(G.neighbors(u))\n",
        "            gamma_u = set(neighbors_u)\n",
        "            gamma_v = set(neighbors_v)\n",
        "            gamma_u.add(u)\n",
        "            gamma_v.add(v)\n",
        "            intersection = len(list(gamma_v.intersection(gamma_u)))\n",
        "            union = len(gamma_u.union(gamma_v))\n",
        "            jaccard_similarity[u][v] = float(intersection)/float(union)\n",
        "        # computing contact strngth\n",
        "        for u in neighbors_v:\n",
        "            N_u = set(G.neighbors(u))\n",
        "            N_v = set(G.neighbors(v))\n",
        "            triangle_count = len(N_u.intersection(N_v))\n",
        "            no_of_triangle = 0\n",
        "            for node1 in neighbors_v:\n",
        "                for node2 in neighbors_v:\n",
        "                    if node1 == node2:\n",
        "                        continue\n",
        "                    if G.has_edge(node1, node2) == True:\n",
        "                        no_of_triangle += 1\n",
        "            no_of_triangle //= 2\n",
        "            if no_of_triangle == 0:\n",
        "                #contact_strength[v][u] = 0.0\n",
        "                if G.degree(v) == 1:\n",
        "                    contact_strength[v][u] = 1.0\n",
        "                else:\n",
        "                    contact_strength[v][u] = 0.0\n",
        "            else:\n",
        "                contact_strength[v][u] = float(triangle_count)/float(no_of_triangle)\n",
        "\n",
        "        # clustering_coffecient = nx.clustering(G)\n",
        "        # computing avarage neighbor degree\n",
        "        total_degree = 0\n",
        "        for u in G.neighbors(v):\n",
        "            total_degree += len(list(G.neighbors(u)))\n",
        "        average_degree[v] = float(total_degree)/(float(no_of_neighbor_v))\n",
        "        #average_degree = nx.average_neighbor_degree(G)\n",
        "        #computing average similarity\n",
        "        total_similarity = 0\n",
        "        for u in neighbors_v:\n",
        "            total_similarity += len(set(G.neighbors(u)).intersection(neighbors_v))/len(set(G.neighbors(u)).union(neighbors_v))\n",
        "        #total_similarity += jaccard_similarity[u][v]\n",
        "        average_similarity[v] = float(total_similarity)/float(no_of_neighbor_v)\n",
        "        # computing information\n",
        "        degree_v = len(neighbors_v)\n",
        "        information[v] = float(degree_v)/float(max_degree)\n",
        "    \n",
        "    Flag = True\n",
        "    Threshold = 0.001\n",
        "    while Flag:\n",
        "        I_max = 0\n",
        "        for v in G.nodes():\n",
        "            information_shared = 0\n",
        "            for u in G.neighbors(v):\n",
        "                # Computing propagation value\n",
        "                propagation_value = f(information[u], information[v])*jaccard_similarity[u][v]*contact_strength[v][u]\n",
        "                # Computing information loss\n",
        "                information_lost = f(information[u], information[v])*(1.0-jaccard_similarity[u][v])*average_similarity[v]/average_degree[v]\n",
        "                if propagation_value < information_lost:\n",
        "                    information_lost = propagation_value\n",
        "                I_in = propagation_value-information_lost\n",
        "                information_shared += I_in\n",
        "                if I_max < I_in:\n",
        "                    I_max = I_in\n",
        "            information[v] += information_shared\n",
        "        if I_max < Threshold:\n",
        "            Flag = False\n",
        "\n",
        "    #community_of_node detection\n",
        "    community_of_node = {}\n",
        "    community_number = 1\n",
        "    Threshold = 0.001\n",
        "    for v in G.nodes():\n",
        "        if v not in community_of_node:\n",
        "            for u in G.neighbors(v):\n",
        "                if abs(information[v]-information[u]) < Threshold:\n",
        "                    if v in community_of_node:\n",
        "                        if u in community_of_node:\n",
        "                            cc = community_of_node[u]\n",
        "                            for node in community_of_node:\n",
        "                                if community_of_node[node] == cc:\n",
        "                                    community_of_node[node] = community_of_node[v]\n",
        "                        else:\n",
        "                            community_of_node[u] = community_of_node[v]\n",
        "                    else:\n",
        "                        if u in community_of_node:\n",
        "                            community_of_node[v] = community_of_node[u]\n",
        "                        else:\n",
        "                            community_of_node[v] = community_number\n",
        "                            community_of_node[u] = community_number\n",
        "                            community_number += 1\n",
        "\n",
        "    for node in G.nodes():\n",
        "        if node not in community_of_node and G.degree(node) == 1:\n",
        "            temp = list(G.neighbors(node))[0]\n",
        "            if temp in community_of_node:\n",
        "                community_of_node[node] = community_of_node[temp]\n",
        "\n",
        "    communities = {}\n",
        "    for node in community_of_node:\n",
        "        if community_of_node[node] not in communities:\n",
        "            communities[community_of_node[node]] = set()\n",
        "        communities[community_of_node[node]].add(node)\n",
        "\n",
        "    comm = []\n",
        "    for i in communities:\n",
        "        comm.append(list(communities[i]))\n",
        "\n",
        "    overlapping_nodes = []\n",
        "    for node in G.nodes():\n",
        "        if node not in community_of_node:\n",
        "            overlapping_nodes.append(node)\n",
        "    return comm"
      ],
      "metadata": {
        "id": "W4g01q3WQqLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## APAL"
      ],
      "metadata": {
        "id": "noI-gEOxUFg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def APAL(G, t=0.0005):\n",
        "    graph = G\n",
        "    communities = dict()\n",
        "    community_count = 0    \n",
        "\n",
        "    def evaluate(candidate_community, threshold):\n",
        "        communities_to_remove = list()\n",
        "        # if intraconnectivity greater than threshold than only we will proceed\n",
        "        if fitness(candidate_community) < threshold:\n",
        "            return\n",
        "        selected_community = None\n",
        "        temporary_max_value = 0\n",
        "        for community in communities:\n",
        "            # Jaccard Index\n",
        "            temporary_value = len(communities[community].intersection(candidate_community)) / len(candidate_community.union(communities[community]))\n",
        "            if candidate_community.issubset(communities[community]):\n",
        "                return\n",
        "            elif communities[community].issubset(candidate_community):\n",
        "                communities_to_remove.append(community)\n",
        "            elif temporary_value > threshold and temporary_value > temporary_max_value and fitness(candidate_community.union(communities[community])) >= threshold:\n",
        "                temporary_max_value = temporary_value\n",
        "                selected_community = community\n",
        "        for community in communities_to_remove:\n",
        "            communities.pop(community)\n",
        "        if selected_community is not None:\n",
        "            communities[selected_community] = candidate_community.union(communities[selected_community])\n",
        "            return\n",
        "        community_count = len(communities) + 1\n",
        "        community_name = \"comm\" + str(community_count)\n",
        "        communities[community_name] = candidate_community\n",
        "\n",
        "    def fitness(candidate_community):  #for finding intraconnectivity\n",
        "        sum_adjacent_vertices = 0\n",
        "        for vertex in candidate_community:\n",
        "            sum_adjacent_vertices += len(set(graph.neighbors(vertex)).intersection(set(candidate_community)))\n",
        "        if sum_adjacent_vertices == 0:\n",
        "            return -1\n",
        "        community_order = len(candidate_community)\n",
        "        # returning value of alpha for each generated candidate community\n",
        "        return sum_adjacent_vertices / (community_order * (community_order - 1))\n",
        "\n",
        "    def run_apal(t):\n",
        "        for vertex in graph.nodes:\n",
        "            # adjacent_vertices = graph.get_adjacency_list(vertex)\n",
        "            adjacent_vertices = graph.neighbors(vertex) \n",
        "            for adjacent_vertex in adjacent_vertices:\n",
        "                set1 = set(adjacent_vertices).difference({adjacent_vertex})\n",
        "                set2 = set(graph.neighbors(adjacent_vertex)).difference({vertex})\n",
        "                community_set = set1.intersection(set2)\n",
        "                if len(community_set) != 0:\n",
        "                    community_set.add(vertex)\n",
        "                    community_set.add(adjacent_vertex)\n",
        "                    evaluate(community_set, t)\n",
        "        return [list(x) for x in communities.values()]\n",
        "    \n",
        "    return run_apal(t)\n"
      ],
      "metadata": {
        "id": "DB9nk4CVUHOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run on all algorithms"
      ],
      "metadata": {
        "id": "-LZiOZB2cQuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path='./sample_data/'\n",
        "filename='15rw_'\n",
        "dataset='55' # dataset number\n",
        "G = nx.Graph()   \n",
        "OG = nx.Graph()\n",
        "edge_file= open(path+filename+'t'+str(dataset)+'.csv','r')\n",
        "edge_list=edge_file.readlines()\n",
        "for edge in edge_list:\n",
        "    edge=edge.split()\n",
        "    G.add_node(int(edge[0]))\n",
        "    G.add_node(int(edge[1]))\n",
        "    G.add_edge(int(edge[0]), int(edge[1]))\n",
        "    \n",
        "    OG.add_node(int(edge[0]))\n",
        "    OG.add_node(int(edge[1]))\n",
        "    OG.add_edge(int(edge[0]), int(edge[1]))\n",
        "\n",
        "run_accuracy = 0\n",
        "if run_accuracy:\n",
        "    gt_file =  open(path+filename+'comm_t'+str(dataset)+'.txt','r')\n",
        "    gt_list=gt_file.readlines()\n",
        "    gt_comm = []\n",
        "    for gt_c in gt_list:\n",
        "        gt_c_list = gt_c.split()\n",
        "        gt_comm.append(list(map(int, gt_c_list)))\n",
        "    gt_comm_node_cluster = NodeClustering(gt_comm, OG, \"\", overlap=True)\n",
        "\n",
        "G=G.to_undirected()\n",
        "OG=OG.to_undirected()\n",
        "\n",
        "# print(\"-----------ERCNS-----------\")\n",
        "# comm = ERCNS(G, 0.05)\n",
        "# print(\"------ Quality Metrics: \")\n",
        "# print(f\"Community Coverage: {community_coverage(OG, comm)}\")\n",
        "# # print(f\"Overlap Coverage: {overlap_coverage(OG, comm)}\")\n",
        "# print(f\"Extended Modularity: {extended_modularity(OG, comm)}\")\n",
        "# print(f\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\")\n",
        "# print(f\"Modularity Overlap: {modularity_overlap(OG, comm)}\")\n",
        "# # print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\n",
        "# if run_accuracy:\n",
        "#     print(\"------ Accuracy Metrics: \")\n",
        "#     comm_node_cluster = NodeClustering(comm, OG, \"\", overlap=True)\n",
        "#     print(f\"NF1: {nf1(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "#     print(f\"ONMI: {onmi(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "#     print(f\"NMI Max: {nmi_max(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"##############################################################\")\n",
        "print(\"-----------LPANNI-----------\")\n",
        "comm = LPANNI(OG)\n",
        "print(\"------ Quality Metrics: \")\n",
        "print(f\"Community Coverage: {community_coverage(OG, comm)}\")\n",
        "# print(f\"Overlap Coverage: {overlap_coverage(OG, comm)}\")\n",
        "print(f\"Extended Modularity: {extended_modularity(OG, comm)}\")\n",
        "print(f\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\")\n",
        "print(f\"Modularity Overlap: {modularity_overlap(OG, comm)}\")\n",
        "# print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\n",
        "if run_accuracy:\n",
        "    print(\"------ Accuracy Metrics: \")\n",
        "    comm_node_cluster = NodeClustering(comm, OG, \"\", overlap=True)\n",
        "    print(f\"NF1: {nf1(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"ONMI: {onmi(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"NMI Max: {nmi_max(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"##############################################################\")\n",
        "print(\"-----------SLPA-----------\")\n",
        "comm = SLPA(OG)\n",
        "print(\"------ Quality Metrics: \")\n",
        "print(f\"Community Coverage: {community_coverage(OG, comm)}\")\n",
        "# print(f\"Overlap Coverage: {overlap_coverage(OG, comm)}\")\n",
        "print(f\"Extended Modularity: {extended_modularity(OG, comm)}\")\n",
        "print(f\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\")\n",
        "print(f\"Modularity Overlap: {modularity_overlap(OG, comm)}\")\n",
        "# print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\n",
        "if run_accuracy:\n",
        "    print(\"------ Accuracy Metrics: \")\n",
        "    comm_node_cluster = NodeClustering(comm, OG, \"\", overlap=True)\n",
        "    print(f\"NF1: {nf1(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"ONMI: {onmi(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"NMI Max: {nmi_max(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"##############################################################\")\n",
        "print(\"-----------Core Expansion-----------\")\n",
        "comm = core_expansion(OG)\n",
        "print(\"------ Quality Metrics: \")\n",
        "print(f\"Community Coverage: {community_coverage(OG, comm)}\")\n",
        "# print(f\"Overlap Coverage: {overlap_coverage(OG, comm)}\")\n",
        "print(f\"Extended Modularity: {extended_modularity(OG, comm)}\")\n",
        "print(f\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\")\n",
        "print(f\"Modularity Overlap: {modularity_overlap(OG, comm)}\")\n",
        "# print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\n",
        "if run_accuracy:\n",
        "    print(\"------ Accuracy Metrics: \")\n",
        "    comm_node_cluster = NodeClustering(comm, OG, \"\", overlap=True)\n",
        "    print(f\"NF1: {nf1(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"ONMI: {onmi(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"NMI Max: {nmi_max(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"##############################################################\")\n",
        "print(\"-----------Walkscan-----------\")\n",
        "comm = walkscan(OG)\n",
        "print(\"------ Quality Metrics: \")\n",
        "print(f\"Community Coverage: {community_coverage(OG, comm)}\")\n",
        "# print(f\"Overlap Coverage: {overlap_coverage(OG, comm)}\")\n",
        "print(f\"Extended Modularity: {extended_modularity(OG, comm)}\")\n",
        "print(f\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\")\n",
        "print(f\"Modularity Overlap: {modularity_overlap(OG, comm)}\")\n",
        "# print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\n",
        "if run_accuracy:\n",
        "    print(\"------ Accuracy Metrics: \")\n",
        "    comm_node_cluster = NodeClustering(comm, OG, \"\", overlap=True)\n",
        "    print(f\"NF1: {nf1(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"ONMI: {onmi(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"NMI Max: {nmi_max(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"##############################################################\")\n",
        "print(\"-----------UMSTMO-----------\")\n",
        "comm = umstmo(OG)\n",
        "print(\"------ Quality Metrics: \")\n",
        "print(f\"Community Coverage: {community_coverage(OG, comm)}\")\n",
        "# print(f\"Overlap Coverage: {overlap_coverage(OG, comm)}\")\n",
        "print(f\"Extended Modularity: {extended_modularity(OG, comm)}\")\n",
        "print(f\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\")\n",
        "print(f\"Modularity Overlap: {modularity_overlap(OG, comm)}\")\n",
        "# print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\n",
        "if run_accuracy:\n",
        "    print(\"------ Accuracy Metrics: \")\n",
        "    comm_node_cluster = NodeClustering(comm, OG, \"\", overlap=True)\n",
        "    print(f\"NF1: {nf1(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"ONMI: {onmi(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"NMI Max: {nmi_max(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"##############################################################\")\n",
        "print(\"-----------OCDID-----------\")\n",
        "comm = OCDID(OG)\n",
        "print(\"------ Quality Metrics: \")\n",
        "print(f\"Community Coverage: {community_coverage(OG, comm)}\")\n",
        "# print(f\"Overlap Coverage: {overlap_coverage(OG, comm)}\")\n",
        "print(f\"Extended Modularity: {extended_modularity(OG, comm)}\")\n",
        "print(f\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\")\n",
        "print(f\"Modularity Overlap: {modularity_overlap(OG, comm)}\")\n",
        "# print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\n",
        "if run_accuracy:\n",
        "    print(\"------ Accuracy Metrics: \")\n",
        "    comm_node_cluster = NodeClustering(comm, OG, \"\", overlap=True)\n",
        "    print(f\"NF1: {nf1(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"ONMI: {onmi(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"NMI Max: {nmi_max(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"##############################################################\")\n",
        "print(\"-----------APAL-----------\")\n",
        "comm = APAL(OG)\n",
        "print(\"------ Quality Metrics: \")\n",
        "print(f\"Community Coverage: {community_coverage(OG, comm)}\")\n",
        "# print(f\"Overlap Coverage: {overlap_coverage(OG, comm)}\")\n",
        "print(f\"Extended Modularity: {extended_modularity(OG, comm)}\")\n",
        "print(f\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\")\n",
        "print(f\"Modularity Overlap: {modularity_overlap(OG, comm)}\")\n",
        "# print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\n",
        "if run_accuracy:\n",
        "    print(\"------ Accuracy Metrics: \")\n",
        "    comm_node_cluster = NodeClustering(comm, OG, \"\", overlap=True)\n",
        "    print(f\"NF1: {nf1(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"ONMI: {onmi(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"NMI Max: {nmi_max(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"##############################################################\")\n",
        "print(\"-----------LPAM-----------\")\n",
        "comm = LPAM(OG)\n",
        "print(\"------ Quality Metrics: \")\n",
        "print(f\"Community Coverage: {community_coverage(OG, comm)}\")\n",
        "# print(f\"Overlap Coverage: {overlap_coverage(OG, comm)}\")\n",
        "print(f\"Extended Modularity: {extended_modularity(OG, comm)}\")\n",
        "print(f\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\")\n",
        "print(f\"Modularity Overlap: {modularity_overlap(OG, comm)}\")\n",
        "# print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\n",
        "if run_accuracy:\n",
        "    print(\"------ Accuracy Metrics: \")\n",
        "    comm_node_cluster = NodeClustering(comm, OG, \"\", overlap=True)\n",
        "    print(f\"NF1: {nf1(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"ONMI: {onmi(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"NMI Max: {nmi_max(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"##############################################################\")\n",
        "print(\"-----------PERCOMVC-----------\")\n",
        "comm = percomvc(OG)\n",
        "print(\"------ Quality Metrics: \")\n",
        "print(f\"Community Coverage: {community_coverage(OG, comm)}\")\n",
        "# print(f\"Overlap Coverage: {overlap_coverage(OG, comm)}\")\n",
        "print(f\"Extended Modularity: {extended_modularity(OG, comm)}\")\n",
        "print(f\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\")\n",
        "print(f\"Modularity Overlap: {modularity_overlap(OG, comm)}\")\n",
        "# print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\n",
        "if run_accuracy:\n",
        "    print(\"------ Accuracy Metrics: \")\n",
        "    comm_node_cluster = NodeClustering(comm, OG, \"\", overlap=True)\n",
        "    print(f\"NF1: {nf1(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"ONMI: {onmi(comm_node_cluster, gt_comm_node_cluster).score}\")\n",
        "    print(f\"NMI Max: {nmi_max(comm_node_cluster, gt_comm_node_cluster).score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1pJvS3VKcNqT",
        "outputId": "7f7635ec-7952-4611-a1cc-54631832c10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "##############################################################\n",
            "-----------LPANNI-----------\n",
            "------ Quality Metrics: \n",
            "Community Coverage: 0.9935627630601634\n",
            "Extended Modularity: 0.7965599861356064\n",
            "Overlapping Modularity: 0.42992618418081885\n",
            "Modularity Overlap: 0.4004468878821984\n",
            "\n",
            "##############################################################\n",
            "-----------SLPA-----------\n",
            "------ Quality Metrics: \n",
            "Community Coverage: 1.0\n",
            "Extended Modularity: 0.766274761134052\n",
            "Overlapping Modularity: 0.43399571376550367\n",
            "Modularity Overlap: 0.21030721184900386\n",
            "\n",
            "##############################################################\n",
            "-----------Core Expansion-----------\n",
            "------ Quality Metrics: \n",
            "Community Coverage: 0.9606338202525377\n",
            "Extended Modularity: 0.4863455457635493\n",
            "Overlapping Modularity: 0.2921789175599105\n",
            "Modularity Overlap: 0.1980297517102382\n",
            "\n",
            "##############################################################\n",
            "-----------Walkscan-----------\n",
            "------ Quality Metrics: \n",
            "Community Coverage: 0.2978460014855162\n",
            "Extended Modularity: 0.2153537716756739\n",
            "Overlapping Modularity: 0.14144639450220295\n",
            "Modularity Overlap: 0.08153962922480536\n",
            "\n",
            "##############################################################\n",
            "-----------UMSTMO-----------\n",
            "------ Quality Metrics: \n",
            "Community Coverage: 0.9480069324090121\n",
            "Extended Modularity: 0.022679804760815332\n",
            "Overlapping Modularity: 0.24993803378858387\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-67eeed7c1209>\u001b[0m in \u001b[0;36m<cell line: 133>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extended Modularity: {extended_modularity(OG, comm)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Overlapping Modularity: {overlapping_modularity(OG, comm)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Modularity Overlap: {modularity_overlap(OG, comm)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;31m# print(f\"Overlapping Permanence: {overlapping_permanence(OG)}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-bf23d9fdafd3>\u001b[0m in \u001b[0;36mmodularity_overlap\u001b[0;34m(G, comm)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mout_comm_connections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                     \u001b[0mout_comm_connections\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}